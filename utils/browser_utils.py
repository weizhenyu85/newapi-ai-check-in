#!/usr/bin/env python3
"""
ÊµèËßàÂô®Ëá™Âä®ÂåñÁõ∏ÂÖ≥ÁöÑÂÖ¨ÂÖ±Â∑•ÂÖ∑ÂáΩÊï∞
"""

import os
import random
from datetime import datetime
from urllib.parse import urlparse


def parse_cookies(cookies_data) -> dict:
    """Ëß£Êûê cookies Êï∞ÊçÆ

    ÊîØÊåÅÂ≠óÂÖ∏Ê†ºÂºèÂíåÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÁöÑ cookies

    Args:
        cookies_data: cookies Êï∞ÊçÆÔºåÂèØ‰ª•ÊòØÂ≠óÂÖ∏ÊàñÂàÜÂè∑ÂàÜÈöîÁöÑÂ≠óÁ¨¶‰∏≤

    Returns:
        Ëß£ÊûêÂêéÁöÑ cookies Â≠óÂÖ∏
    """
    if isinstance(cookies_data, dict):
        return cookies_data

    if isinstance(cookies_data, str):
        cookies_dict = {}
        for cookie in cookies_data.split(";"):
            if "=" in cookie:
                key, value = cookie.strip().split("=", 1)
                cookies_dict[key] = value
        return cookies_dict
    return {}


def filter_cookies(cookies: list[dict], origin: str) -> dict:
    """Ê†πÊçÆ origin ËøáÊª§ cookiesÔºåÂè™‰øùÁïôÂåπÈÖçÂüüÂêçÁöÑ cookies

    Args:
        cookies: Camoufox cookies ÂàóË°®ÔºåÊØè‰∏™ÂÖÉÁ¥†ÊòØÂåÖÂê´ name, value, domain Á≠âÁöÑÂ≠óÂÖ∏
        origin: Provider ÁöÑ origin URL (‰æãÂ¶Ç: https://api.example.com)

    Returns:
        ËøáÊª§ÂêéÁöÑ cookies Â≠óÂÖ∏ {name: value}
    """
    # ÊèêÂèñ provider origin ÁöÑÂüüÂêç
    provider_domain = urlparse(origin).netloc

    # ËøáÊª§ cookiesÔºåÂè™‰øùÁïô‰∏é provider domain ÂåπÈÖçÁöÑ
    user_cookies = {}
    matched_items = []  # Â≠òÂÇ® "name(domain)" Ê†ºÂºè
    filtered_items = []  # Â≠òÂÇ® "name(domain)" Ê†ºÂºè

    for cookie in cookies:
        cookie_name = cookie.get("name")
        cookie_value = cookie.get("value")
        cookie_domain = cookie.get("domain", "")

        if cookie_name and cookie_value:
            # Ê£ÄÊü• cookie domain ÊòØÂê¶ÂåπÈÖç provider domain
            # cookie domain ÂèØËÉΩ‰ª• . ÂºÄÂ§¥ (Â¶Ç .example.com)ÔºåÈúÄË¶ÅÂ§ÑÁêÜ
            normalized_cookie_domain = cookie_domain.lstrip(".")
            normalized_provider_domain = provider_domain.lstrip(".")

            # ÂåπÈÖçÈÄªËæëÔºöcookie domain Â∫îËØ•ÊòØ provider domain ÁöÑÂêéÁºÄ
            if (
                normalized_provider_domain == normalized_cookie_domain
                or normalized_provider_domain.endswith("." + normalized_cookie_domain)
                or normalized_cookie_domain.endswith("." + normalized_provider_domain)
            ):
                user_cookies[cookie_name] = cookie_value
                matched_items.append(f"{cookie_name}({cookie_domain})")
            else:
                filtered_items.append(f"{cookie_name}({cookie_domain})")

    if matched_items:
        print(f"  üîµ Matched: {', '.join(matched_items)}")
    if filtered_items:
        print(f"  üî¥ Filtered: {', '.join(filtered_items)}")

    print(
        f"üîç Cookie filtering result ({provider_domain}): "
        f"{len(matched_items)} matched, {len(filtered_items)} filtered"
    )

    return user_cookies


def get_random_user_agent() -> str:
    """Ëé∑ÂèñÈöèÊú∫ÁöÑÁé∞‰ª£ÊµèËßàÂô® User Agent Â≠óÁ¨¶‰∏≤

    Returns:
        ÈöèÊú∫ÈÄâÊã©ÁöÑ User Agent Â≠óÁ¨¶‰∏≤
    """
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 " "(KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:134.0) " "Gecko/20100101 Firefox/134.0",
    ]
    return random.choice(user_agents)


async def take_screenshot(
    page,
    reason: str,
    account_name: str,
    screenshots_dir: str = "screenshots",
) -> None:
    """Êà™ÂèñÂΩìÂâçÈ°µÈù¢ÁöÑÂ±èÂπïÊà™Âõæ

    Args:
        page: Camoufox/Playwright È°µÈù¢ÂØπË±°
        reason: Êà™ÂõæÂéüÂõ†ÊèèËø∞
        account_name: Ë¥¶Âè∑ÂêçÁß∞ÔºàÁî®‰∫éÊó•ÂøóËæìÂá∫ÂíåÊñá‰ª∂ÂêçÔºâ
        screenshots_dir: Êà™Âõæ‰øùÂ≠òÁõÆÂΩïÔºåÈªòËÆ§‰∏∫ "screenshots"
    """
    try:
        os.makedirs(screenshots_dir, exist_ok=True)

        # Ëá™Âä®ÁîüÊàêÂÆâÂÖ®ÁöÑË¥¶Âè∑ÂêçÁß∞
        safe_account_name = "".join(c if c.isalnum() else "_" for c in account_name)

        # ÁîüÊàêÊñá‰ª∂Âêç: Ë¥¶Âè∑Âêç_Êó∂Èó¥Êà≥_ÂéüÂõ†.png
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_reason = "".join(c if c.isalnum() else "_" for c in reason)
        filename = f"{safe_account_name}_{timestamp}_{safe_reason}.png"
        filepath = os.path.join(screenshots_dir, filename)

        await page.screenshot(path=filepath, full_page=True)
        print(f"üì∏ {account_name}: Screenshot saved to {filepath}")
    except Exception as e:
        print(f"‚ö†Ô∏è {account_name}: Failed to take screenshot: {e}")


async def save_page_content_to_file(
    page,
    reason: str,
    account_name: str,
    prefix: str = "",
    logs_dir: str = "logs",
) -> None:
    """‰øùÂ≠òÈ°µÈù¢ HTML Âà∞Êó•ÂøóÊñá‰ª∂

    Args:
        page: Camoufox/Playwright È°µÈù¢ÂØπË±°
        reason: Êó•ÂøóÂéüÂõ†ÊèèËø∞
        account_name: Ë¥¶Âè∑ÂêçÁß∞ÔºàÁî®‰∫éÊó•ÂøóËæìÂá∫ÂíåÊñá‰ª∂ÂêçÔºâ
        prefix: Êñá‰ª∂ÂêçÂâçÁºÄÔºàÂ¶Ç "github_", "linuxdo_" Á≠âÔºâ
        logs_dir: Êó•Âøó‰øùÂ≠òÁõÆÂΩïÔºåÈªòËÆ§‰∏∫ "logs"
    """
    try:
        os.makedirs(logs_dir, exist_ok=True)

        # Ëá™Âä®ÁîüÊàêÂÆâÂÖ®ÁöÑË¥¶Âè∑ÂêçÁß∞
        safe_account_name = "".join(c if c.isalnum() else "_" for c in account_name)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_reason = "".join(c if c.isalnum() else "_" for c in reason)
        
        # ÊûÑÂª∫Êñá‰ª∂Âêç
        if prefix:
            filename = f"{safe_account_name}_{timestamp}_{prefix}_{safe_reason}.html"
        else:
            filename = f"{safe_account_name}_{timestamp}_{safe_reason}.html"
        filepath = os.path.join(logs_dir, filename)

        html_content = await page.content()
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(html_content)

        print(f"üìÑ {account_name}: Page HTML saved to {filepath}")
    except Exception as e:
        print(f"‚ö†Ô∏è {account_name}: Failed to save HTML: {e}")


async def aliyun_captcha_check(page, account_name: str) -> bool:
    """ÈòøÈáå‰∫ëÈ™åËØÅÁ†ÅÊ£ÄÊü•ÂíåÂ§ÑÁêÜ

    Ê£ÄÊü•È°µÈù¢ÊòØÂê¶ÊúâÈòøÈáå‰∫ëÈ™åËØÅÁ†ÅÔºàÈÄöËøá traceid Ê£ÄÊµãÔºâÔºåÂ¶ÇÊûúÊúâÂàôÂ∞ùËØïËá™Âä®ÊªëÂä®È™åËØÅ

    Args:
        page: Camoufox/Playwright È°µÈù¢ÂØπË±°
        account_name: Ë¥¶Âè∑ÂêçÁß∞ÔºàÁî®‰∫éÊó•ÂøóËæìÂá∫Ôºâ

    Returns:
        bool: È™åËØÅÁ†ÅÂ§ÑÁêÜÊòØÂê¶ÊàêÂäüÔºàÊó†È™åËØÅÁ†ÅÊàñÈ™åËØÅÈÄöËøáËøîÂõû TrueÔºåÈ™åËØÅÂ§±Ë¥•ËøîÂõû FalseÔºâ
    """
    # Ê£ÄÊü•ÊòØÂê¶Êúâ traceid (ÈòøÈáå‰∫ëÈ™åËØÅÁ†ÅÈ°µÈù¢)
    try:
        traceid = await page.evaluate(
            """() => {
            const traceElement = document.getElementById('traceid');
            if (traceElement) {
                const text = traceElement.innerText || traceElement.textContent;
                const match = text.match(/TraceID:\\s*([a-f0-9]+)/i);
                return match ? match[1] : null;
            }
            return null;
        }"""
        )

        if traceid:
            print(f"‚ö†Ô∏è {account_name}: Aliyun captcha detected, traceid: {traceid}")
            try:
                await page.wait_for_selector("#nocaptcha", timeout=60000)

                slider_element = await page.query_selector("#nocaptcha .nc_scale")
                if slider_element:
                    slider = await slider_element.bounding_box()
                    print(f"‚ÑπÔ∏è {account_name}: Slider bounding box: {slider}")

                slider_handle = await page.query_selector("#nocaptcha .btn_slide")
                if slider_handle:
                    handle = await slider_handle.bounding_box()
                    print(f"‚ÑπÔ∏è {account_name}: Slider handle bounding box: {handle}")

                if slider and handle:
                    await take_screenshot(page, "aliyun_captcha_slider_start", account_name)

                    await page.mouse.move(
                        handle.get("x") + handle.get("width") / 2,
                        handle.get("y") + handle.get("height") / 2,
                    )
                    await page.mouse.down()
                    await page.mouse.move(
                        handle.get("x") + slider.get("width"),
                        handle.get("y") + handle.get("height") / 2,
                        steps=2,
                    )
                    await page.mouse.up()
                    await take_screenshot(page, "aliyun_captcha_slider_completed", account_name)

                    # Wait for page to be fully loaded
                    await page.wait_for_timeout(20000)

                    await take_screenshot(page, "aliyun_captcha_slider_result", account_name)
                    return True
                else:
                    print(f"‚ùå {account_name}: Slider or handle not found")
                    await take_screenshot(page, "aliyun_captcha_error", account_name)
                    return False
            except Exception as e:
                print(f"‚ùå {account_name}: Error occurred while moving slider, {e}")
                await take_screenshot(page, "aliyun_captcha_error", account_name)
                return False
        else:
            print(f"‚ÑπÔ∏è {account_name}: No traceid found")
            await take_screenshot(page, "aliyun_captcha_traceid_found", account_name)
            return True
    except Exception as e:
        print(f"‚ùå {account_name}: Error occurred while getting traceid, {e}")
        await take_screenshot(page, "aliyun_captcha_error", account_name)
        return False
